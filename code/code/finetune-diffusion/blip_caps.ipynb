{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 07:12:14.617227: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-24 07:12:14.698140: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-24 07:12:15.134219: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-24 07:12:15.134260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-24 07:12:15.134265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7265829d4bc4eb5966e872e0bddc56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushanth/anaconda3/envs/llt/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 captions so far...\n",
      "Saved 200 captions so far...\n",
      "Saved 300 captions so far...\n",
      "Saved 400 captions so far...\n",
      "Saved 500 captions so far...\n",
      "Saved 600 captions so far...\n",
      "Saved 700 captions so far...\n",
      "Saved 800 captions so far...\n",
      "Saved 900 captions so far...\n",
      "Saved 1000 captions so far...\n",
      "Saved 1100 captions so far...\n",
      "Saved 1200 captions so far...\n",
      "Saved 1300 captions so far...\n",
      "Saved 1400 captions so far...\n",
      "Saved 1500 captions so far...\n",
      "Saved 1600 captions so far...\n",
      "Saved 1700 captions so far...\n",
      "Saved 1800 captions so far...\n",
      "Saved 1900 captions so far...\n",
      "Saved 2000 captions so far...\n",
      "Saved 2100 captions so far...\n",
      "Saved 2200 captions so far...\n",
      "Saved 2300 captions so far...\n",
      "Saved 2400 captions so far...\n",
      "Saved 2500 captions so far...\n",
      "Saved 2600 captions so far...\n",
      "Saved 2700 captions so far...\n",
      "Saved 2800 captions so far...\n",
      "Saved 2900 captions so far...\n",
      "Saved 3000 captions so far...\n",
      "Saved 3100 captions so far...\n",
      "Saved 3200 captions so far...\n",
      "Saved 3300 captions so far...\n",
      "Saved 3400 captions so far...\n",
      "Saved 3500 captions so far...\n",
      "Saved 3600 captions so far...\n",
      "Saved 3700 captions so far...\n",
      "Saved 3800 captions so far...\n",
      "Saved 3900 captions so far...\n",
      "Saved 4000 captions so far...\n",
      "Saved 4100 captions so far...\n",
      "Saved 4200 captions so far...\n",
      "Saved 4300 captions so far...\n",
      "Saved 4400 captions so far...\n",
      "Saved 4500 captions so far...\n",
      "Saved 4600 captions so far...\n",
      "Saved 4700 captions so far...\n",
      "Saved 4800 captions so far...\n",
      "Saved 4900 captions so far...\n",
      "Saved 5000 captions so far...\n",
      "Saved 5100 captions so far...\n",
      "Saved 5200 captions so far...\n",
      "Saved 5300 captions so far...\n",
      "Saved 5400 captions so far...\n",
      "Saved 5500 captions so far...\n",
      "Saved 5600 captions so far...\n",
      "Saved 5700 captions so far...\n",
      "Saved 5800 captions so far...\n",
      "Saved 5900 captions so far...\n",
      "Saved 6000 captions so far...\n",
      "Saved 6100 captions so far...\n",
      "Saved 6200 captions so far...\n",
      "Saved 6300 captions so far...\n",
      "Saved 6400 captions so far...\n",
      "Saved 6500 captions so far...\n",
      "Saved 6600 captions so far...\n",
      "Saved 6700 captions so far...\n",
      "Saved 6800 captions so far...\n",
      "Saved 6900 captions so far...\n",
      "Saved 7000 captions so far...\n",
      "Saved 7100 captions so far...\n",
      "Saved 7200 captions so far...\n",
      "Saved 7300 captions so far...\n",
      "Saved 7400 captions so far...\n",
      "Saved 7500 captions so far...\n",
      "Saved 7600 captions so far...\n",
      "Saved 7700 captions so far...\n",
      "Saved 7800 captions so far...\n",
      "Saved 7900 captions so far...\n",
      "Saved 8000 captions so far...\n",
      "Saved 8100 captions so far...\n",
      "Saved 8200 captions so far...\n",
      "Saved 8300 captions so far...\n",
      "Saved 8400 captions so far...\n",
      "Saved 8500 captions so far...\n",
      "Saved 8600 captions so far...\n",
      "Saved 8700 captions so far...\n",
      "Saved 8800 captions so far...\n",
      "Saved 8900 captions so far...\n",
      "Saved 9000 captions so far...\n",
      "Saved 9100 captions so far...\n",
      "Saved 9200 captions so far...\n",
      "Saved 9300 captions so far...\n",
      "Saved 9400 captions so far...\n",
      "Saved 9500 captions so far...\n",
      "Saved 9600 captions so far...\n",
      "Saved 9700 captions so far...\n",
      "Saved 9800 captions so far...\n",
      "Saved 9900 captions so far...\n",
      "Saved 10000 captions so far...\n",
      "Saved 10100 captions so far...\n",
      "Saved 10200 captions so far...\n",
      "Saved 10300 captions so far...\n",
      "Saved 10400 captions so far...\n",
      "Saved 10500 captions so far...\n",
      "Saved 10600 captions so far...\n",
      "Saved 10700 captions so far...\n",
      "Saved 10800 captions so far...\n",
      "Saved 10900 captions so far...\n",
      "Saved 11000 captions so far...\n",
      "Saved 11100 captions so far...\n",
      "Saved 11200 captions so far...\n",
      "Saved 11300 captions so far...\n",
      "Saved 11400 captions so far...\n",
      "Saved 11500 captions so far...\n",
      "Saved 11600 captions so far...\n",
      "Saved 11700 captions so far...\n",
      "Saved 11800 captions so far...\n",
      "Saved 11900 captions so far...\n",
      "Saved 12000 captions so far...\n",
      "Saved 12100 captions so far...\n",
      "Saved 12200 captions so far...\n",
      "Saved 12300 captions so far...\n",
      "Saved 12400 captions so far...\n",
      "Saved 12500 captions so far...\n",
      "Saved 12600 captions so far...\n",
      "Saved 12700 captions so far...\n",
      "Saved 12800 captions so far...\n",
      "Saved 12900 captions so far...\n",
      "Saved 13000 captions so far...\n",
      "Saved 13100 captions so far...\n",
      "Saved 13200 captions so far...\n",
      "Saved 13300 captions so far...\n",
      "Saved 13400 captions so far...\n",
      "Saved 13500 captions so far...\n",
      "Saved 13600 captions so far...\n",
      "Saved 13700 captions so far...\n",
      "Saved 13800 captions so far...\n",
      "Saved 13900 captions so far...\n",
      "Saved 14000 captions so far...\n",
      "Saved 14100 captions so far...\n",
      "Saved 14200 captions so far...\n",
      "Saved 14300 captions so far...\n",
      "Saved 14400 captions so far...\n",
      "Saved 14500 captions so far...\n",
      "Saved 14600 captions so far...\n",
      "Saved 14700 captions so far...\n",
      "Saved 14800 captions so far...\n",
      "Saved 14900 captions so far...\n",
      "Saved 15000 captions so far...\n",
      "Saving captions to captions1.json...\n",
      "Saved 15100 captions so far...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import signal\n",
    "from PIL import Image\n",
    "import torch\n",
    "import transformers\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Check if GPU is available and use it if so\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the BLIP-2 processor and model\n",
    "processor = transformers.Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = transformers.Blip2ForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip2-opt-2.7b\", load_in_8bit=True, device_map={\"\": 0}, torch_dtype=torch.float16\n",
    ")\n",
    "#model.to(device)\n",
    "\n",
    "# Function to generate captions for an image\n",
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = np.array(image)  # Convert to NumPy array\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    generated_ids = model.generate(**inputs)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "    return generated_text\n",
    "\n",
    "# Path to your image directory (replace with your actual path)\n",
    "image_dir = \"/mnt/data/tarun/celeba_hq_256\"\n",
    "\n",
    "# Initialize an empty dictionary to store image-caption pairs\n",
    "captions = {}\n",
    "\n",
    "# Define a signal handler function\n",
    "def save_and_exit(signum, frame):\n",
    "    print(\"Saving captions to captions1.json...\")\n",
    "    with open(\"captions1.json\", \"w\") as outfile:\n",
    "        json.dump(captions, outfile, indent=4)\n",
    "    exit(0)\n",
    "\n",
    "# Register the signal handler\n",
    "signal.signal(signal.SIGINT, save_and_exit)  # Handle Ctrl+C\n",
    "\n",
    "# Loop through all images in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        caption = generate_caption(image_path)\n",
    "        captions[image_path] = caption\n",
    "\n",
    "        # Save captions periodically (optional)\n",
    "        if len(captions) % 100 == 0:  # Save every 100 captions\n",
    "            print(f\"Saved {len(captions)} captions so far...\")\n",
    "            with open(\"captions1.json\", \"w\") as outfile:\n",
    "                json.dump(captions, outfile, indent=4)\n",
    "\n",
    "# Save captions if the loop finishes normally\n",
    "with open(\"captions1.json\", \"w\") as outfile:\n",
    "    json.dump(captions, outfile, indent=4)\n",
    "\n",
    "print(\"Captions saved successfully to captions1.json!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llt",
   "language": "python",
   "name": "llt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
